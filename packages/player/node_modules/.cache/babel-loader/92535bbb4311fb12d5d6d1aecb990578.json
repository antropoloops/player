{"ast":null,"code":"import debug from \"debug\";\nimport { AudioContext } from \"standardized-audio-context\";\nconst log = debug(\"atpls:context\");\nconst activeListeners = [];\nconst context = new AudioContext();\ncontext.onstatechange = handleStateChange;\nhandleStateChange();\nautoUnlockAudio();\n\nfunction handleStateChange() {\n  const state = context.state;\n  log(\"state %s\", state);\n\n  if (state === \"running\") {\n    const listeners = activeListeners.slice();\n    activeListeners.length = 0;\n    listeners.forEach(listener => listener(context));\n  }\n}\n\nfunction autoUnlockAudio() {\n  function unlock() {} // Setup a touch start listener to attempt an unlock in.\n\n\n  document.addEventListener(\"touchstart\", unlock, true);\n  document.addEventListener(\"touchend\", unlock, true);\n  document.addEventListener(\"click\", unlock, true);\n}\n/**\n * @see https://developers.google.com/web/updates/2017/09/autoplay-policy-changes#webaudio\n */\n\n\nexport function getActiveAudioContext() {\n  if (context.state === \"running\") {\n    return Promise.resolve(context);\n  } else {\n    return new Promise(resolve => {\n      activeListeners.push(resolve);\n    });\n  }\n}\n\nfunction startAudioContext(ctx) {\n  log(\"start context\"); // iOS hack. See https://github.com/tambien/StartAudioContext/blob/master/StartAudioContext.js\n\n  const buffer = ctx.createBuffer(1, 1, ctx.sampleRate);\n  const source = ctx.createBufferSource();\n  source.buffer = buffer;\n  source.connect(ctx.destination);\n  source.start(0);\n  return ctx;\n}","map":{"version":3,"sources":["/Users/dani/Antropoloops/atpls-player/src/player/AudioContext.ts"],"names":["debug","AudioContext","log","activeListeners","context","onstatechange","handleStateChange","autoUnlockAudio","state","listeners","slice","length","forEach","listener","unlock","document","addEventListener","getActiveAudioContext","Promise","resolve","push","startAudioContext","ctx","buffer","createBuffer","sampleRate","source","createBufferSource","connect","destination","start"],"mappings":"AAAA,OAAOA,KAAP,MAAkB,OAAlB;AACA,SAASC,YAAT,QAA6B,4BAA7B;AAEA,MAAMC,GAAG,GAAGF,KAAK,CAAC,eAAD,CAAjB;AAGA,MAAMG,eAAiC,GAAG,EAA1C;AACA,MAAMC,OAAO,GAAG,IAAIH,YAAJ,EAAhB;AACAG,OAAO,CAACC,aAAR,GAAwBC,iBAAxB;AAEAA,iBAAiB;AACjBC,eAAe;;AAEf,SAASD,iBAAT,GAA6B;AAC3B,QAAME,KAAK,GAAGJ,OAAO,CAACI,KAAtB;AACAN,EAAAA,GAAG,CAAC,UAAD,EAAaM,KAAb,CAAH;;AACA,MAAIA,KAAK,KAAK,SAAd,EAAyB;AACvB,UAAMC,SAAS,GAAGN,eAAe,CAACO,KAAhB,EAAlB;AACAP,IAAAA,eAAe,CAACQ,MAAhB,GAAyB,CAAzB;AACAF,IAAAA,SAAS,CAACG,OAAV,CAAkBC,QAAQ,IAAIA,QAAQ,CAACT,OAAD,CAAtC;AACD;AACF;;AAED,SAASG,eAAT,GAA2B;AACzB,WAASO,MAAT,GAAkB,CAAE,CADK,CAGzB;;;AACAC,EAAAA,QAAQ,CAACC,gBAAT,CAA0B,YAA1B,EAAwCF,MAAxC,EAAgD,IAAhD;AACAC,EAAAA,QAAQ,CAACC,gBAAT,CAA0B,UAA1B,EAAsCF,MAAtC,EAA8C,IAA9C;AACAC,EAAAA,QAAQ,CAACC,gBAAT,CAA0B,OAA1B,EAAmCF,MAAnC,EAA2C,IAA3C;AACD;AAED;;;;;AAGA,OAAO,SAASG,qBAAT,GAAwD;AAC7D,MAAIb,OAAO,CAACI,KAAR,KAAkB,SAAtB,EAAiC;AAC/B,WAAOU,OAAO,CAACC,OAAR,CAAgBf,OAAhB,CAAP;AACD,GAFD,MAEO;AACL,WAAO,IAAIc,OAAJ,CAA0BC,OAAO,IAAI;AAC1ChB,MAAAA,eAAe,CAACiB,IAAhB,CAAqBD,OAArB;AACD,KAFM,CAAP;AAGD;AACF;;AAED,SAASE,iBAAT,CAA2BC,GAA3B,EAA4D;AAC1DpB,EAAAA,GAAG,CAAC,eAAD,CAAH,CAD0D,CAE1D;;AACA,QAAMqB,MAAM,GAAGD,GAAG,CAACE,YAAJ,CAAiB,CAAjB,EAAoB,CAApB,EAAuBF,GAAG,CAACG,UAA3B,CAAf;AACA,QAAMC,MAAM,GAAGJ,GAAG,CAACK,kBAAJ,EAAf;AACAD,EAAAA,MAAM,CAACH,MAAP,GAAgBA,MAAhB;AACAG,EAAAA,MAAM,CAACE,OAAP,CAAeN,GAAG,CAACO,WAAnB;AACAH,EAAAA,MAAM,CAACI,KAAP,CAAa,CAAb;AACA,SAAOR,GAAP;AACD","sourcesContent":["import debug from \"debug\";\nimport { AudioContext } from \"standardized-audio-context\";\n\nconst log = debug(\"atpls:context\");\n\ntype ResolveContext = (value: AudioContext) => void;\nconst activeListeners: ResolveContext[] = [];\nconst context = new AudioContext();\ncontext.onstatechange = handleStateChange;\n\nhandleStateChange();\nautoUnlockAudio();\n\nfunction handleStateChange() {\n  const state = context.state;\n  log(\"state %s\", state);\n  if (state === \"running\") {\n    const listeners = activeListeners.slice();\n    activeListeners.length = 0;\n    listeners.forEach(listener => listener(context));\n  }\n}\n\nfunction autoUnlockAudio() {\n  function unlock() {}\n\n  // Setup a touch start listener to attempt an unlock in.\n  document.addEventListener(\"touchstart\", unlock, true);\n  document.addEventListener(\"touchend\", unlock, true);\n  document.addEventListener(\"click\", unlock, true);\n}\n\n/**\n * @see https://developers.google.com/web/updates/2017/09/autoplay-policy-changes#webaudio\n */\nexport function getActiveAudioContext(): Promise<AudioContext> {\n  if (context.state === \"running\") {\n    return Promise.resolve(context);\n  } else {\n    return new Promise<AudioContext>(resolve => {\n      activeListeners.push(resolve);\n    });\n  }\n}\n\nfunction startAudioContext(ctx: AudioContext): AudioContext {\n  log(\"start context\");\n  // iOS hack. See https://github.com/tambien/StartAudioContext/blob/master/StartAudioContext.js\n  const buffer = ctx.createBuffer(1, 1, ctx.sampleRate);\n  const source = ctx.createBufferSource();\n  source.buffer = buffer;\n  source.connect(ctx.destination);\n  source.start(0);\n  return ctx;\n}\n"]},"metadata":{},"sourceType":"module"}